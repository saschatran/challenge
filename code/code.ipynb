{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "\n",
    "import process_gini as pg\n",
    "import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704313, 15)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/skylab_instagram_datathon_dataset.csv\", sep=\";\")\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>period_end_date</th>\n",
       "      <th>compset_group</th>\n",
       "      <th>compset</th>\n",
       "      <th>business_entity_doing_business_as_name</th>\n",
       "      <th>legal_entity_name</th>\n",
       "      <th>domicile_country_name</th>\n",
       "      <th>ultimate_parent_legal_entity_name</th>\n",
       "      <th>primary_exchange_name</th>\n",
       "      <th>calculation_type</th>\n",
       "      <th>followers</th>\n",
       "      <th>pictures</th>\n",
       "      <th>videos</th>\n",
       "      <th>comments</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>704313</td>\n",
       "      <td>704313</td>\n",
       "      <td>704313</td>\n",
       "      <td>704313</td>\n",
       "      <td>704313</td>\n",
       "      <td>676558</td>\n",
       "      <td>458589</td>\n",
       "      <td>676558</td>\n",
       "      <td>458589</td>\n",
       "      <td>704313</td>\n",
       "      <td>5.792580e+05</td>\n",
       "      <td>695803.000000</td>\n",
       "      <td>684349.000000</td>\n",
       "      <td>6.953430e+05</td>\n",
       "      <td>6.959770e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>455</td>\n",
       "      <td>20</td>\n",
       "      <td>54</td>\n",
       "      <td>706</td>\n",
       "      <td>423</td>\n",
       "      <td>26</td>\n",
       "      <td>401</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Weekly</td>\n",
       "      <td>2023-07-08</td>\n",
       "      <td>Luxury &amp; Premium &amp; Mainstream</td>\n",
       "      <td>US Softlines Analyst Interest List</td>\n",
       "      <td>All Brands</td>\n",
       "      <td>LVMH Moet Hennessy Louis Vuitton SE</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>LVMH Moet Hennessy Louis Vuitton SE</td>\n",
       "      <td>New York Stock Exchange</td>\n",
       "      <td>Metric Value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>704313</td>\n",
       "      <td>1635</td>\n",
       "      <td>216241</td>\n",
       "      <td>113744</td>\n",
       "      <td>27755</td>\n",
       "      <td>27576</td>\n",
       "      <td>193509</td>\n",
       "      <td>27576</td>\n",
       "      <td>132071</td>\n",
       "      <td>704313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.342432e+07</td>\n",
       "      <td>344.272540</td>\n",
       "      <td>61.244426</td>\n",
       "      <td>3.043246e+04</td>\n",
       "      <td>2.163189e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.106975e+08</td>\n",
       "      <td>2777.396873</td>\n",
       "      <td>564.468480</td>\n",
       "      <td>2.766459e+05</td>\n",
       "      <td>1.803193e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.013372e+05</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.710000e+02</td>\n",
       "      <td>1.727700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.104144e+06</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.435000e+03</td>\n",
       "      <td>9.318400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.479325e+06</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.872000e+03</td>\n",
       "      <td>4.577470e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.502565e+09</td>\n",
       "      <td>141746.000000</td>\n",
       "      <td>35905.000000</td>\n",
       "      <td>1.732046e+07</td>\n",
       "      <td>7.120711e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        period period_end_date                  compset_group  \\\n",
       "count   704313          704313                         704313   \n",
       "unique       1             455                             20   \n",
       "top     Weekly      2023-07-08  Luxury & Premium & Mainstream   \n",
       "freq    704313            1635                         216241   \n",
       "mean       NaN             NaN                            NaN   \n",
       "std        NaN             NaN                            NaN   \n",
       "min        NaN             NaN                            NaN   \n",
       "25%        NaN             NaN                            NaN   \n",
       "50%        NaN             NaN                            NaN   \n",
       "75%        NaN             NaN                            NaN   \n",
       "max        NaN             NaN                            NaN   \n",
       "\n",
       "                                   compset  \\\n",
       "count                               704313   \n",
       "unique                                  54   \n",
       "top     US Softlines Analyst Interest List   \n",
       "freq                                113744   \n",
       "mean                                   NaN   \n",
       "std                                    NaN   \n",
       "min                                    NaN   \n",
       "25%                                    NaN   \n",
       "50%                                    NaN   \n",
       "75%                                    NaN   \n",
       "max                                    NaN   \n",
       "\n",
       "       business_entity_doing_business_as_name  \\\n",
       "count                                  704313   \n",
       "unique                                    706   \n",
       "top                                All Brands   \n",
       "freq                                    27755   \n",
       "mean                                      NaN   \n",
       "std                                       NaN   \n",
       "min                                       NaN   \n",
       "25%                                       NaN   \n",
       "50%                                       NaN   \n",
       "75%                                       NaN   \n",
       "max                                       NaN   \n",
       "\n",
       "                          legal_entity_name     domicile_country_name  \\\n",
       "count                                676558                    458589   \n",
       "unique                                  423                        26   \n",
       "top     LVMH Moet Hennessy Louis Vuitton SE  United States of America   \n",
       "freq                                  27576                    193509   \n",
       "mean                                    NaN                       NaN   \n",
       "std                                     NaN                       NaN   \n",
       "min                                     NaN                       NaN   \n",
       "25%                                     NaN                       NaN   \n",
       "50%                                     NaN                       NaN   \n",
       "75%                                     NaN                       NaN   \n",
       "max                                     NaN                       NaN   \n",
       "\n",
       "          ultimate_parent_legal_entity_name    primary_exchange_name  \\\n",
       "count                                676558                   458589   \n",
       "unique                                  401                       30   \n",
       "top     LVMH Moet Hennessy Louis Vuitton SE  New York Stock Exchange   \n",
       "freq                                  27576                   132071   \n",
       "mean                                    NaN                      NaN   \n",
       "std                                     NaN                      NaN   \n",
       "min                                     NaN                      NaN   \n",
       "25%                                     NaN                      NaN   \n",
       "50%                                     NaN                      NaN   \n",
       "75%                                     NaN                      NaN   \n",
       "max                                     NaN                      NaN   \n",
       "\n",
       "       calculation_type     followers       pictures         videos  \\\n",
       "count            704313  5.792580e+05  695803.000000  684349.000000   \n",
       "unique                1           NaN            NaN            NaN   \n",
       "top        Metric Value           NaN            NaN            NaN   \n",
       "freq             704313           NaN            NaN            NaN   \n",
       "mean                NaN  1.342432e+07     344.272540      61.244426   \n",
       "std                 NaN  1.106975e+08    2777.396873     564.468480   \n",
       "min                 NaN  0.000000e+00       0.000000       0.000000   \n",
       "25%                 NaN  3.013372e+05      19.000000       2.000000   \n",
       "50%                 NaN  1.104144e+06      44.000000       7.000000   \n",
       "75%                 NaN  4.479325e+06     122.000000      20.000000   \n",
       "max                 NaN  3.502565e+09  141746.000000   35905.000000   \n",
       "\n",
       "            comments         likes  \n",
       "count   6.953430e+05  6.959770e+05  \n",
       "unique           NaN           NaN  \n",
       "top              NaN           NaN  \n",
       "freq             NaN           NaN  \n",
       "mean    3.043246e+04  2.163189e+06  \n",
       "std     2.766459e+05  1.803193e+07  \n",
       "min     0.000000e+00  0.000000e+00  \n",
       "25%     3.710000e+02  1.727700e+04  \n",
       "50%     1.435000e+03  9.318400e+04  \n",
       "75%     5.872000e+03  4.577470e+05  \n",
       "max     1.732046e+07  7.120711e+08  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# information about the data before processing it -> run again after processing\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READJUST STRINGS\n",
    "\n",
    "# remove leading and trailing whitespaces and convert to lowercase\n",
    "df = df.map(lambda x: x.strip().lower() if isinstance(x, str) else x)\n",
    "\n",
    "# replace all double whitespaces with single whitespaces\n",
    "df = df.map(lambda x: x.replace(\"  \", \" \") if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the 'period_end_of_week' column to datetime\n",
    "df['period_end_date'] = pd.to_datetime(df['period_end_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE DOMICILE_COUNTRY_NAME\n",
    "\n",
    "# replace the china;hong kong with hong kong\n",
    "df['domicile_country_name'] = df['domicile_country_name'].replace('china;hong kong', 'hong kong')\n",
    "\n",
    "# remove the sign \";\" in column domicile_country_name\n",
    "df['domicile_country_name'] = df['domicile_country_name'].str.replace(';', '')\n",
    "\n",
    "# if empty, fill with nan\n",
    "df['domicile_country_name'] = df['domicile_country_name'].replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE PRIMARY_EXCHANGE_NAME\n",
    "\n",
    "# remove the sign \";\" in column domicile_country_name\n",
    "df['primary_exchange_name'] = df['primary_exchange_name'].str.replace(';', '')\n",
    "\n",
    "# if empty, fill with nan\n",
    "df['primary_exchange_name'] = df['primary_exchange_name'].replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE ULTIMATE_PARENT_LEGAL_ENTITY_NAME\n",
    "df['ultimate_parent_legal_entity_name'] = df['ultimate_parent_legal_entity_name'].replace('Anheuser-Busch;Anheuser-Busch', 'Anheuser-Busch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"All_Brands\" and \"Don't Use it\"\n",
    "df = df[df[\"business_entity_doing_business_as_name\"] != \"all brands\"]\n",
    "# TODO: Remove \"Don't Use it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary columns\n",
    "# Here: 'period', 'calculation_type'\n",
    "df = df.drop(columns=['period', 'calculation_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14304/591243391.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Group_Null' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna('Group_Null', inplace=True)\n",
      "/tmp/ipykernel_14304/591243391.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace('Group_Null', np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# certain entries have exact data except of \"compset\"\n",
    "# we want to take the union of all of them\n",
    "\n",
    "grouping_columns = [col for col in df.columns if col != 'compset']\n",
    "\n",
    "df.fillna('Group_Null', inplace=True)\n",
    "result = df.groupby(grouping_columns).agg({'compset': lambda x: set(x)}).reset_index()\n",
    "df = result\n",
    "df.replace('Group_Null', np.nan, inplace=True)\n",
    "\n",
    "\n",
    "# df.describe(include='all')\n",
    "\n",
    "# to test\n",
    "#result[(result[\"business_entity_doing_business_as_name\"] == \"24S\") & (result[\"period_end_date\"] == \"2017-05-13\")]\n",
    "#result[(result[\"business_entity_doing_business_as_name\"] == \"dd's Discounts\") & (result[\"period_end_date\"] == \"2023-09-09\")]\n",
    "#result[(result[\"business_entity_doing_business_as_name\"] == \"dd's Discounts\") & (result[\"period_end_date\"] == \"2023-09-16\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298040, 13)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the date into year, month, day\n",
    "df['Year'] = df['period_end_date'].dt.year\n",
    "df['Month'] = df['period_end_date'].dt.month\n",
    "df['Day'] = df['period_end_date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the difference between the current date and the previous date\n",
    "df = df.sort_values(by=['business_entity_doing_business_as_name', 'period_end_date'])\n",
    "df['date_diff_prev'] = df['period_end_date'].diff().dt.days\n",
    "df['date_diff_prev'] = df['date_diff_prev'].fillna(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total involvement\n",
    "df[\"total_involvement\"] = df[\"comments\"] + df[\"likes\"]\n",
    "df[\"total_company_activity\"] = df[\"pictures\"] + df[\"videos\"]\n",
    "\n",
    "df[\"conversion_rate_total\"] = df[\"total_involvement\"] / df[\"followers\"]\n",
    "\n",
    "# COntent type\n",
    "df[\"ratio_of_videos\"] = df[\"videos\"] / (df[\"pictures\"] + df[\"videos\"])\n",
    "df[\"ratio_of_pictures\"] = df[\"pictures\"] / (df[\"pictures\"] + df[\"videos\"])\n",
    "\n",
    "# ASSUMTION: we only like videos / photos from this week\n",
    "df[\"likes_per_picture\"] = df[\"likes\"] / df[\"pictures\"]\n",
    "df[\"likes_per_video\"] =   df[\"likes\"] / df[\"videos\"]\n",
    "df[\"comments_per_picture\"] =  df[\"comments\"] / df[\"pictures\"] \n",
    "df[\"comments_per_video\"] =   df[\"comments\"] / df[\"videos\"]\n",
    "\n",
    "# take care of zeros\n",
    "df.loc[df[\"pictures\"] + df[\"videos\"] == 0, \"ratio_of_videos\"] = np.nan\n",
    "df.loc[df[\"pictures\"] + df[\"videos\"] == 0, \"ratio_of_pictures\"] = np.nan\n",
    "\n",
    "df.loc[df[\"pictures\"] == 0, \"likes_per_picture\"] = np.nan\n",
    "df.loc[df[\"videos\"] == 0, \"likes_per_video\"] = np.nan\n",
    "df.loc[df[\"pictures\"] == 0, \"comments_per_picture\"] = np.nan\n",
    "df.loc[df[\"videos\"] == 0, \"comments_per_video\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD GINI\n",
    "reload(pg)\n",
    "\n",
    "df_gini = pg.process_gini(df)\n",
    "df = pd.merge(df, df_gini, left_on=['domicile_country_name', 'Year'], right_on=['Country Name', 'Year'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['period_end_date', 'compset_group',\n",
       "       'business_entity_doing_business_as_name', 'legal_entity_name',\n",
       "       'domicile_country_name', 'ultimate_parent_legal_entity_name',\n",
       "       'primary_exchange_name', 'followers', 'pictures', 'videos', 'comments',\n",
       "       'likes', 'compset', 'Year', 'Month', 'Day', 'date_diff_prev',\n",
       "       'total_involvement', 'total_company_activity', 'conversion_rate_total',\n",
       "       'ratio_of_videos', 'ratio_of_pictures', 'likes_per_picture',\n",
       "       'likes_per_video', 'comments_per_picture', 'comments_per_video',\n",
       "       'Country Name', 'Gene Index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations / Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of ... over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_by = ['followers', 'pictures', 'videos', 'comments',\n",
    "       'likes',\n",
    "       'total_involvement', 'total_company_activity', 'conversion_rate_total',\n",
    "       'ratio_of_videos', 'ratio_of_pictures', 'likes_per_picture',\n",
    "       'likes_per_video', 'comments_per_picture', 'comments_per_video']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'datetime_end_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[268], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m reload(plots)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agg \u001b[38;5;129;01min\u001b[39;00m agg_by:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mplots\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_aggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/src/code/plots.py:7\u001b[0m, in \u001b[0;36mtotal_aggregate\u001b[0;34m(df, agg_by)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtotal_aggregate\u001b[39m(df, agg_by):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Aggregating likes per date\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     aggregated_data \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatetime_end_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[agg_by]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Plotting\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/pandas/core/frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9186\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9189\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/pandas/core/groupby/grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'datetime_end_date'"
     ]
    }
   ],
   "source": [
    "reload(plots)\n",
    "for agg in agg_by:\n",
    "    plots.total_aggregate(df, agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

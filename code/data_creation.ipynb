{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Notebook\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "The objective of this notebook is to create the dataset (<bold> ../data/data_preparation_output.csv </bold>), used subsequenially in the analysis & data visualizaion\n",
    "</div>\n",
    "\n",
    "\n",
    "1. Data standardisation\n",
    "    1. text\n",
    "        - lowercase\n",
    "        - ltrim\n",
    "2. Data cleaning\n",
    "    1. encoding as missing values\n",
    "    2. outlier detection\n",
    "3. Feature creation\n",
    "    1. conversion rate\n",
    "    2. competition in the market\n",
    "    3. miscellaneous\n",
    "4. Data enhancement\n",
    "    1. stock prices\n",
    "    2. country value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "import os\n",
    "\n",
    "import process_gini as pg\n",
    "import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../individualNotebooks/skylab_instagram_datathon_dataset.csv\"  # ASY local path\n",
    "# path = \"../data/skylab_instagram_datathon_dataset.csv\" # gen\n",
    "df = pd.read_csv(path, sep=\";\")\n",
    "# df = pd.read_csv(path.replace(\"/\", os.sep), sep=\";\") # for Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READJUST STRINGS\n",
    "string_vars = [\"compset_group\", \"compset\", \"business_entity_doing_business_as_name\",\n",
    "\"legal_entity_name\", \"domicile_country_name\", \"ultimate_parent_legal_entity_name\",\n",
    "\"primary_exchange_name\"]\n",
    "\n",
    "for varname in df.columns:\n",
    "    # 1. remove leading and trailing whitespaces and convert to lowercase\n",
    "    df[varname] = df[varname].apply(lambda x: x.strip().lower() if isinstance(x, str) else x)\n",
    "    # 2. replace all double whitespaces with single whitespaces\n",
    "    df[varname] = df[varname].apply(lambda x: x.replace(\"  \", \" \") if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the 'period_end_of_week' column to datetime\n",
    "df['period_end_date'] = pd.to_datetime(df['period_end_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE DOMICILE_COUNTRY_NAME\n",
    "\n",
    "# replace the china;hong kong with hong kong\n",
    "df['domicile_country_name'] = df['domicile_country_name'].replace('china;hong kong', 'hong kong')\n",
    "\n",
    "# remove the sign \";\" in column domicile_country_name\n",
    "df['domicile_country_name'] = df['domicile_country_name'].str.replace(';', '')\n",
    "\n",
    "# if empty, fill with nan\n",
    "df['domicile_country_name'] = df['domicile_country_name'].replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE PRIMARY_EXCHANGE_NAME\n",
    "\n",
    "# remove the sign \";\" in column domicile_country_name\n",
    "df['primary_exchange_name'] = df['primary_exchange_name'].str.replace(';', '')\n",
    "\n",
    "# if empty, fill with nan\n",
    "df['primary_exchange_name'] = df['primary_exchange_name'].replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE ULTIMATE_PARENT_LEGAL_ENTITY_NAME\n",
    "df['ultimate_parent_legal_entity_name'] = df['ultimate_parent_legal_entity_name'].replace('Anheuser-Busch;Anheuser-Busch', 'Anheuser-Busch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary columns\n",
    "# Here: 'period', 'calculation_type'\n",
    "df = df.drop(columns=['period', 'calculation_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Assumption:</b> All Brands represent the aggregated on all brands in the corresponding compset => delete it </b>\n",
    "</div>\n",
    "(checked in the sell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#varnames_resp = ['followers','pictures', 'videos', 'comments']\n",
    "\n",
    "#df1 = df.loc[df[\"business_entity_doing_business_as_name\"] == \"all brands\"].sort_values(['period_end_date','compset_group', 'compset'])[['period_end_date','compset_group', 'compset', 'followers','pictures', 'videos', 'comments']]\n",
    "#df2 = df.loc[df[\"business_entity_doing_business_as_name\"] != \"all brands\"].sort_values(['period_end_date','compset_group', 'compset'])[['period_end_date','compset_group', 'compset', 'followers','pictures', 'videos', 'comments']]\n",
    "#df2 = df2.groupby(['period_end_date','compset_group', 'compset']).sum()\n",
    "\n",
    "#df1.join(df2, on=['period_end_date','compset_group', 'compset'], rsuffix='_compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"All_Brands\" \n",
    "df = df[df[\"business_entity_doing_business_as_name\"] != \"all brands\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Assumption:</b> if the value of ultimate_parent_legal_entity_name is 'do not use' (0.17%) it means not to use the entity name and not the entire row</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'do not use'\n",
    "#sum(df[\"ultimate_parent_legal_entity_name\"] == 'do not use') / len(df)\n",
    "df.loc[df[\"ultimate_parent_legal_entity_name\"] == 'do not use', \"ultimate_parent_legal_entity_name\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# certain entries have exact data except of \"compset\"\n",
    "# we want to take the union of all of them\n",
    "\n",
    "grouping_columns = [col for col in df.columns if col != 'compset']\n",
    "\n",
    "df.fillna('Group_Null', inplace=True)\n",
    "result = df.groupby(grouping_columns).agg({'compset': lambda x: set(x)}).reset_index()\n",
    "df = result\n",
    "df.replace('Group_Null', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some data related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the date into year, month, day\n",
    "df['Year'] = df['period_end_date'].dt.year\n",
    "df['Month'] = df['period_end_date'].dt.month\n",
    "df['Day'] = df['period_end_date'].dt.day\n",
    "df['Weekday'] = df['period_end_date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add variables related to ownership structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ultimate_parent_vs_legal_entity\"] = df[\"ultimate_parent_legal_entity_name\"] != df[\"legal_entity_name\"]\n",
    "df[\"ultimate_parent_vs_business_entity\"] = df[\"ultimate_parent_legal_entity_name\"] != df[\"business_entity_doing_business_as_name\"]\n",
    "df[\"legal_entity_vs_business_entity\"] = df[\"legal_entity_name\"] != df[\"business_entity_doing_business_as_name\"]\n",
    "df[\"same_ownership\"] = (df[\"legal_entity_name\"] == df[\"ultimate_parent_legal_entity_name\"]) & (df[\"legal_entity_name\"] == df[\"business_entity_doing_business_as_name\"])\n",
    "# get the difference between the current date and the previous date\n",
    "#df = df.sort_values(by=['business_entity_doing_business_as_name', 'period_end_date'])\n",
    "#df['date_diff_prev'] = df['period_end_date'].diff().dt.days\n",
    "#df['date_diff_prev'] = df['date_diff_prev'].fillna(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion Rate Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Assumption:</b> likes and comments are only for the videos and pictures uploaded within the same week</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total involevement\n",
    "df[\"total_involvement\"] = df[\"comments\"] + df[\"likes\"]\n",
    "df[\"total_company_activity\"] = df[\"pictures\"] + df[\"videos\"]\n",
    "\n",
    "df[\"conversion_rate_total\"] = df[\"total_involvement\"] / df[\"followers\"]\n",
    "df[\"return_on_activity\"] = df[\"total_company_activity\"] / df[\"total_involvement\"] \n",
    "\n",
    "# COntent type\n",
    "df[\"ratio_of_videos\"] = df[\"videos\"] / (df[\"pictures\"] + df[\"videos\"])\n",
    "df[\"ratio_of_pictures\"] = df[\"pictures\"] / (df[\"pictures\"] + df[\"videos\"])\n",
    "\n",
    "# ASSUMTION: we only like videos / photos from this week\n",
    "df[\"likes_per_picture\"] = df[\"likes\"] / df[\"pictures\"]\n",
    "df[\"likes_per_video\"] =   df[\"likes\"] / df[\"videos\"]\n",
    "df[\"comments_per_picture\"] =  df[\"comments\"] / df[\"pictures\"] \n",
    "df[\"comments_per_video\"] =   df[\"comments\"] / df[\"videos\"]\n",
    "\n",
    "# take care of zeros\n",
    "df.loc[df[\"pictures\"] + df[\"videos\"] == 0, \"ratio_of_videos\"] = np.nan\n",
    "df.loc[df[\"pictures\"] + df[\"videos\"] == 0, \"ratio_of_pictures\"] = np.nan\n",
    "\n",
    "df.loc[df[\"pictures\"] == 0, \"likes_per_picture\"] = np.nan\n",
    "df.loc[df[\"videos\"] == 0, \"likes_per_video\"] = np.nan\n",
    "df.loc[df[\"pictures\"] == 0, \"comments_per_picture\"] = np.nan\n",
    "df.loc[df[\"videos\"] == 0, \"comments_per_video\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Competition Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_aggreg = [\"followers\", \"videos\", \"pictures\", \"likes\", \"comments\"]\n",
    "\n",
    "vars_agg_ind = [\"period_end_date\", \"compset_group\", \"business_entity_doing_business_as_name\"]\n",
    "vars_agg_ind_small = [\"period_end_date\", \"compset_group\"]\n",
    "\n",
    "vars_agg_ind_country = [\"period_end_date\", \"compset_group\", \"domicile_country_name\", \"business_entity_doing_business_as_name\"]\n",
    "vars_agg_ind_country_small = [\"period_end_date\", \"compset_group\", \"domicile_country_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_ind = df.drop_duplicates(vars_agg_ind).groupby(vars_agg_ind_small)\n",
    "df_group_ind_country = df.drop_duplicates(vars_agg_ind_country).groupby(vars_agg_ind_country_small)\n",
    "\n",
    "df_cnt_industry = pd.DataFrame(df_group_ind.count()[\"business_entity_doing_business_as_name\"])\n",
    "df_cnt_industry_country = pd.DataFrame(df_group_ind_country.count()[\"business_entity_doing_business_as_name\"])\n",
    "df_sum_industry = df_group_ind.sum()[vars_to_aggreg]\n",
    "df_sum_industry_country = df_group_ind_country.sum()[vars_to_aggreg]\n",
    "\n",
    "# rename variables before the join\n",
    "df_cnt_industry.rename(lambda x: x + \"_cnt_industry\", axis='columns', inplace=True)\n",
    "df_cnt_industry_country.rename(lambda x: x + \"_cnt_industry_country\", axis='columns', inplace=True)\n",
    "df_sum_industry.rename(lambda x: x + \"_sum_industry\", axis='columns', inplace=True)\n",
    "df_sum_industry_country.rename(lambda x: x + \"_sum_industry_country\", axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the join\n",
    "df = df.join(df_cnt_industry, on=vars_agg_ind_small)\n",
    "df = df.join(df_cnt_industry_country, on=vars_agg_ind_country_small)\n",
    "df = df.join(df_sum_industry, on=vars_agg_ind_small)\n",
    "df = df.join(df_sum_industry_country, on=vars_agg_ind_country_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created fraction_followers_sum_industry from followers and followers_sum_industry\n",
      "Created fraction_followers_sum_industry_country from followers and followers_sum_industry_country\n",
      "Created fraction_videos_sum_industry from videos and videos_sum_industry\n",
      "Created fraction_videos_sum_industry_country from videos and videos_sum_industry_country\n",
      "Created fraction_pictures_sum_industry from pictures and pictures_sum_industry\n",
      "Created fraction_pictures_sum_industry_country from pictures and pictures_sum_industry_country\n",
      "Created fraction_likes_sum_industry from likes and likes_sum_industry\n",
      "Created fraction_likes_sum_industry_country from likes and likes_sum_industry_country\n",
      "Created fraction_comments_sum_industry from comments and comments_sum_industry\n",
      "Created fraction_comments_sum_industry_country from comments and comments_sum_industry_country\n"
     ]
    }
   ],
   "source": [
    "# creating ratios\n",
    "vars_to_create = [\"followers\", \"videos\", \"pictures\", \"likes\", \"comments\"]\n",
    "\n",
    "for varname in vars_to_create:\n",
    "    # define varnames\n",
    "    # input\n",
    "    aggreg_ind = varname + \"_sum_industry\"\n",
    "    aggreg_ind_country = varname + \"_sum_industry_country\"\n",
    "    # output\n",
    "    out_agg_ind = \"fraction_\" + aggreg_ind\n",
    "    out_agg_ind_country = \"fraction_\" + aggreg_ind_country\n",
    "    # compute fraction\n",
    "    df[out_agg_ind] = df[varname] / df[aggreg_ind]\n",
    "    df[out_agg_ind_country] =  df[varname] / df[aggreg_ind_country]\n",
    "    # add missing values\n",
    "    df.loc[df[aggreg_ind] == 0, out_agg_ind] = np.nan\n",
    "    df.loc[df[aggreg_ind_country] == 0, out_agg_ind_country] = np.nan\n",
    "    # print status\n",
    "    print(f\"Created {out_agg_ind} from {varname} and {aggreg_ind}\")\n",
    "    print(f\"Created {out_agg_ind_country} from {varname} and {aggreg_ind_country}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lagged Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Assumption: </b> the first available observation for the company coincides with the first week the company has opened its instagram account\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating lag_1_followers\n",
      "Creating lag_1_pictures\n",
      "Creating lag_1_videos\n",
      "Creating lag_1_comments\n"
     ]
    }
   ],
   "source": [
    "df.sort_values([\"business_entity_doing_business_as_name\", 'period_end_date'], inplace=True) \n",
    "\n",
    "lag_size = 1\n",
    "\n",
    "for lag_var in ['followers', 'pictures', 'videos', 'comments']:\n",
    "    print(f'Creating lag_{lag_size}_{lag_var}')\n",
    "    df[f'lag_{lag_size}_{lag_var}'] = df[lag_var].shift(lag_size)\n",
    "    df[f'lag_{lag_size}_date'] = df['period_end_date'].shift(lag_size)  # to check the time difference\n",
    "    df[f'lag_{lag_size}_company'] = df[\"business_entity_doing_business_as_name\"].shift(lag_size)\n",
    "    df[f'timediff_{lag_size}'] = df['period_end_date'] - df[f'lag_{lag_size}_date']\n",
    "    df[f'timediff_{lag_size}'] = df[f'timediff_{lag_size}'].apply(lambda x: x.days // 7)\n",
    "    # set to 0 the ones where company has changed\n",
    "    # ASSUMPTION HERE\n",
    "    df.loc[ df[f'lag_{lag_size}_company'] != df[\"business_entity_doing_business_as_name\"], f'lag_{lag_size}_{lag_var}']  = 0\n",
    "    df.loc[ df[f'lag_{lag_size}_company'] != df[\"business_entity_doing_business_as_name\"], f'lag_{lag_size}_date']  = np.nan\n",
    "    # Change compared to the last week\n",
    "    df[f'diff_{lag_size}_{lag_var}'] = df[lag_var] - df[f'lag_{lag_size}_{lag_var}']\n",
    "    #df.loc[ df[f'timediff_{lag_size}'] != lag_size, f'lag_{lag_size}_{lag_var}']  = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD GINI\n",
    "reload(pg)\n",
    "\n",
    "df_gini = pg.process_gini(df)\n",
    "df = pd.merge(df, df_gini, left_on=['domicile_country_name', 'Year'], right_on=['Country Name', 'Year'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['period_end_date', f'diff_{lag_size}_{lag_var}']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filepath = '../data/data_preparation_output.csv'\n",
    "df.to_csv(output_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
